from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import sounddevice as sd
import numpy as np
import asyncio
from typing import Optional, Dict, List
import logging
from dataclasses import dataclass
import time
from queue import Queue
import threading
from contextlib import asynccontextmanager
import pyaudio

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("TTSService")

class AudioConfig:
    """Audio configuration for Seeed ReSpeaker"""
    RATE = 48000  # Native rate for Seeed ReSpeaker
    CHANNELS = 2
    FORMAT = pyaudio.paFloat32
    CHUNK = 4096  # Optimized for Pi 5
    BUFFER_SIZE = 8192

class QueueItem:
    """Represents a queued audio item"""
    def __init__(self, audio_data: np.ndarray, sample_rate: int):
        self.id = f"audio_{int(time.time() * 1000)}"
        self.audio_data = audio_data
        self.sample_rate = sample_rate
        self.timestamp = time.time()
        self.status = "queued"

class AudioQueue:
    """Manages the audio playback queue"""
    def __init__(self, audio_config: AudioConfig):
        self.config = audio_config
        self.queue: Queue = Queue()
        self.items: Dict[str, QueueItem] = {}
        self.currently_playing: Optional[str] = None
        self.is_playing = threading.Event()
        self._stop_requested = threading.Event()
        self._player_thread = None
        self._pa = None
        self._stream = None
        self._setup_audio()

    def _setup_audio(self):
        """Initialize PyAudio with Seeed ReSpeaker configuration"""
        try:
            self._pa = pyaudio.PyAudio()
            
            # Find Seeed ReSpeaker device
            device_index = None
            for i in range(self._pa.get_device_count()):
                dev_info = self._pa.get_device_info_by_index(i)
                if 'seeed' in dev_info['name'].lower():
                    device_index = i
                    logger.info(f"Found Seeed ReSpeaker device: {dev_info['name']}")
                    break

            # Fall back to default device if ReSpeaker not found
            if device_index is None:
                device_index = self._pa.get_default_output_device_info()['index']
                logger.info("Using default output device")

            # Open audio stream
            self._stream = self._pa.open(
                rate=self.config.RATE,
                channels=self.config.CHANNELS,
                format=self.config.FORMAT,
                output=True,
                output_device_index=device_index,
                frames_per_buffer=self.config.CHUNK,
                start=False
            )
            
        except Exception as e:
            logger.error(f"Error setting up audio: {e}")
            self.cleanup()
            raise

    def start(self):
        """Start the audio player thread"""
        self._stop_requested.clear()
        self._player_thread = threading.Thread(target=self._player_worker, daemon=True)
        self._player_thread.start()

    def _player_worker(self):
        """Worker thread for playing audio"""
        while not self._stop_requested.is_set():
            try:
                if not self.queue.empty() and self._stream:
                    item = self.queue.get()
                    self.currently_playing = item.id
                    self.is_playing.set()
                    item.status = "playing"

                    try:
                        # Resample if needed
                        if item.sample_rate != self.config.RATE:
                            audio_data = self._resample_audio(
                                item.audio_data, 
                                item.sample_rate, 
                                self.config.RATE
                            )
                        else:
                            audio_data = item.audio_data

                        # Convert to stereo if mono
                        if len(audio_data.shape) == 1:
                            audio_data = np.column_stack((audio_data, audio_data))

                        # Start stream if not started
                        if not self._stream.is_active():
                            self._stream.start_stream()

                        # Play audio in chunks
                        for i in range(0, len(audio_data), self.config.CHUNK):
                            if self._stop_requested.is_set():
                                break
                            chunk = audio_data[i:i + self.config.CHUNK]
                            if len(chunk) < self.config.CHUNK:
                                # Pad last chunk if needed
                                chunk = np.pad(
                                    chunk, 
                                    ((0, self.config.CHUNK - len(chunk)), (0, 0))
                                )
                            self._stream.write(chunk.tobytes())

                        item.status = "completed"

                    except Exception as e:
                        logger.error(f"Playback error: {e}")
                        item.status = "failed"
                    finally:
                        if self._stream and self._stream.is_active():
                            self._stream.stop_stream()

                    self.currently_playing = None
                    self.is_playing.clear()
                else:
                    time.sleep(0.1)

            except Exception as e:
                logger.error(f"Player worker error: {e}")
                time.sleep(0.1)

    def _resample_audio(self, audio_data: np.ndarray, src_rate: int, dst_rate: int) -> np.ndarray:
        """Simple linear resampling"""
        if src_rate == dst_rate:
            return audio_data

        duration = len(audio_data) / src_rate
        time_old = np.linspace(0, duration, len(audio_data))
        time_new = np.linspace(0, duration, int(len(audio_data) * dst_rate / src_rate))
        
        if len(audio_data.shape) == 2:  # Stereo
            resampled = np.zeros((len(time_new), 2))
            for channel in range(2):
                resampled[:, channel] = np.interp(time_new, time_old, audio_data[:, channel])
        else:  # Mono
            resampled = np.interp(time_new, time_old, audio_data)
            
        return resampled

    def add_item(self, audio_data: np.ndarray, sample_rate: int) -> str:
        """Add audio to the queue"""
        item = QueueItem(audio_data, sample_rate)
        self.items[item.id] = item
        self.queue.put(item)
        return item.id

    def stop(self):
        """Stop playback and clear queue"""
        self._stop_requested.set()
        if self._stream:
            self._stream.stop_stream()
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except:
                pass
        self.currently_playing = None
        self.is_playing.clear()

    def cleanup(self):
        """Clean up audio resources"""
        self.stop()
        if self._stream:
            self._stream.close()
        if self._pa:
            self._pa.terminate()
        self._stream = None
        self._pa = None

    def get_status(self) -> dict:
        """Get current queue status"""
        return {
            "currently_playing": self.currently_playing,
            "queue_size": self.queue.qsize(),
            "is_playing": self.is_playing.is_set(),
            "items": [
                {
                    "id": id,
                    "status": item.status,
                    "queued_at": item.timestamp
                }
                for id, item in self.items.items()
            ]
        }
        
class AudioRequest(BaseModel):
    """Audio request model"""
    audio_data: List[float]
    sample_rate: int = 22050

class TextRequest(BaseModel):
    """Text request model"""
    text: str

class AudioConfig:
    """Audio configuration for Seeed ReSpeaker"""
    RATE = 48000  # Native rate for Seeed ReSpeaker
    CHANNELS = 2
    FORMAT = pyaudio.paFloat32
    CHUNK = 4096  # Optimized for Pi 5
    BUFFER_SIZE = 8192

class PiperTTSConfig:
    """Piper TTS configuration"""
    MODEL_PATH = "./piper-models/sv-se-nst-medium.onnx"
    CONFIG_PATH = "./piper-models/sv-se-nst-medium.onnx.json"
    SAMPLE_RATE = 22050  # Piper's native rate

class PiperTTSHandler:
    """Handles Piper TTS operations"""
    def __init__(self, config: PiperTTSConfig):
        self.config = config
        self._voice = None
        self._setup_piper()
        
    def _setup_piper(self):
        """Initialize Piper TTS"""
        try:
            if not os.path.exists(self.config.MODEL_PATH):
                raise FileNotFoundError(f"Piper model not found at {self.config.MODEL_PATH}")
            if not os.path.exists(self.config.CONFIG_PATH):
                raise FileNotFoundError(f"Piper config not found at {self.config.CONFIG_PATH}")
                
            self._voice = PiperVoice.load(self.config.MODEL_PATH, self.config.CONFIG_PATH)
            logger.info("Piper TTS initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Piper TTS: {e}")
            raise

    def synthesize(self, text: str) -> Tuple[np.ndarray, int]:
        """Synthesize text to audio using Piper"""
        try:
            # Create temporary WAV file
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_path = temp_wav.name

            try:
                # Generate audio with Piper
                with wave.open(temp_path, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # Mono
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(self.config.SAMPLE_RATE)
                    self._voice.synthesize(text, wav_file)

                # Read the generated audio
                with wave.open(temp_path, 'rb') as wav_file:
                    audio_data = np.frombuffer(wav_file.readframes(wav_file.getnframes()), dtype=np.int16)
                    # Convert to float32 and normalize
                    audio_data = audio_data.astype(np.float32) / 32768.0

                return audio_data, self.config.SAMPLE_RATE

            finally:
                # Clean up temporary file
                try:
                    os.unlink(temp_path)
                except Exception as e:
                    logger.error(f"Error removing temporary file: {e}")

        except Exception as e:
            logger.error(f"Error synthesizing text: {e}")
            raise

    def cleanup(self):
        """Clean up Piper resources"""
        self._voice = None

class AudioService:
    """Main audio service"""
    def __init__(self):
        self.config = AudioConfig()
        self.piper_config = PiperTTSConfig()
        self.queue = AudioQueue(self.config)
        self.piper = PiperTTSHandler(self.piper_config)
        
    async def start(self):
        """Start the service"""
        self.queue.start()
        
    def cleanup(self):
        """Cleanup resources"""
        self.queue.cleanup()
        self.piper.cleanup()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    service = AudioService()
    app.state.service = service
    await service.start()
    yield
    # Shutdown
    service.cleanup()

app = FastAPI(lifespan=lifespan)

@app.post("/play")
async def play_audio(request: AudioRequest):
    """Queue audio for playback"""
    try:
        service = app.state.service
        audio_data = np.array(request.audio_data, dtype=np.float32)
        task_id = service.queue.add_item(audio_data, request.sample_rate)
        return {"task_id": task_id}
    except Exception as e:
        logger.error(f"Error in play_audio: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/stop")
async def stop_playback():
    """Stop playback and clear queue"""
    try:
        service = app.state.service
        service.queue.stop()
        return {"status": "stopped"}
    except Exception as e:
        logger.error(f"Error in stop_playback: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
@app.post("/text")
async def synthesize_text(request: TextRequest):
    """Synthesize and queue text for playback"""
    try:
        service = app.state.service
        # Synthesize text to audio using Piper
        audio_data, sample_rate = service.piper.synthesize(request.text)
        # Queue the audio for playback
        task_id = service.queue.add_item(audio_data, sample_rate)
        return {"task_id": task_id}
    except Exception as e:
        logger.error(f"Error in synthesize_text: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8912,
        log_level="info"
    )

@app.get("/status")
async def get_status():
    """Get service status"""
    try:
        service = app.state.service
        return service.queue.get_status()
    except Exception as e:
        logger.error(f"Error in get_status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8912,
        log_level="info"
    )